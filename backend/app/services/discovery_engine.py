"""
Discovery Engine Service

AI-powered clean energy breakthrough discovery using Claude Opus 4.5.

Capabilities:
- Hypothesis generation (50-200 hypotheses per problem)
- Literature synthesis from multiple databases
- Patent landscape analysis
- Materials property screening
- Cross-domain innovation identification
"""

import asyncio
import json
from datetime import datetime
from typing import Any, AsyncGenerator
from dataclasses import dataclass, field
from enum import Enum

from app.services.ai_service import ai_service
from app.core.config import settings


class DiscoveryStatus(str, Enum):
    """Status of a discovery run."""
    PENDING = "pending"
    GENERATING_HYPOTHESES = "generating_hypotheses"
    SEARCHING_LITERATURE = "searching_literature"
    ANALYZING_PATENTS = "analyzing_patents"
    SEARCHING_MATERIALS = "searching_materials"
    SYNTHESIZING = "synthesizing"
    COMPLETED = "completed"
    FAILED = "failed"


@dataclass
class Hypothesis:
    """A research hypothesis generated by the Discovery Engine."""
    id: str
    title: str
    statement: str
    rationale: str
    feasibility: int  # 1-10
    novelty: int  # 1-10
    impact: int  # 1-10
    combined_score: float
    key_references: list[str] = field(default_factory=list)
    materials: list[str] = field(default_factory=list)
    next_steps: list[str] = field(default_factory=list)
    category: str = "general"

    def to_dict(self) -> dict:
        return {
            "id": self.id,
            "title": self.title,
            "statement": self.statement,
            "rationale": self.rationale,
            "feasibility": self.feasibility,
            "novelty": self.novelty,
            "impact": self.impact,
            "combined_score": self.combined_score,
            "key_references": self.key_references,
            "materials": self.materials,
            "next_steps": self.next_steps,
            "category": self.category,
        }


@dataclass
class DiscoveryProgress:
    """Progress tracking for a discovery run."""
    status: DiscoveryStatus
    progress_percent: int
    current_step: str
    hypotheses_generated: int = 0
    papers_found: int = 0
    patents_found: int = 0
    materials_found: int = 0
    error_message: str | None = None

    def to_dict(self) -> dict:
        return {
            "status": self.status.value,
            "progress_percent": self.progress_percent,
            "current_step": self.current_step,
            "hypotheses_generated": self.hypotheses_generated,
            "papers_found": self.papers_found,
            "patents_found": self.patents_found,
            "materials_found": self.materials_found,
            "error_message": self.error_message,
        }


@dataclass
class DiscoveryResult:
    """Complete results from a discovery run."""
    discovery_id: str
    problem_statement: str
    constraints: dict[str, Any]
    hypotheses: list[Hypothesis]
    literature_synthesis: dict[str, Any] | None
    patent_landscape: dict[str, Any] | None
    materials_analysis: dict[str, Any] | None
    executive_summary: str
    top_recommendation: str
    immediate_actions: list[str]
    medium_term_actions: list[str]
    long_term_vision: str
    risk_factors: list[dict[str, str]]
    processing_time_seconds: float
    created_at: datetime

    def to_dict(self) -> dict:
        return {
            "discovery_id": self.discovery_id,
            "problem_statement": self.problem_statement,
            "constraints": self.constraints,
            "hypotheses": [h.to_dict() for h in self.hypotheses],
            "total_hypotheses": len(self.hypotheses),
            "high_priority_count": len([h for h in self.hypotheses if h.combined_score >= 7.0]),
            "literature_synthesis": self.literature_synthesis,
            "patent_landscape": self.patent_landscape,
            "materials_analysis": self.materials_analysis,
            "executive_summary": self.executive_summary,
            "top_recommendation": self.top_recommendation,
            "immediate_actions": self.immediate_actions,
            "medium_term_actions": self.medium_term_actions,
            "long_term_vision": self.long_term_vision,
            "risk_factors": self.risk_factors,
            "processing_time_seconds": self.processing_time_seconds,
            "created_at": self.created_at.isoformat(),
        }


class DiscoveryEngine:
    """
    AI-powered Discovery Engine for clean energy breakthroughs.

    Uses Claude Opus 4.5 for:
    - Deep reasoning and hypothesis generation
    - Cross-domain synthesis
    - Literature analysis
    - Strategic recommendations
    """

    def __init__(self):
        self._progress_callbacks: dict[str, list] = {}

    async def generate_hypotheses(
        self,
        problem_statement: str,
        constraints: dict[str, Any] | None = None,
        context: str | None = None,
        num_hypotheses: int = 50,
    ) -> list[Hypothesis]:
        """
        Generate research hypotheses using Claude Opus 4.5.

        Args:
            problem_statement: The research problem to solve
            constraints: Optional constraints (budget, timeline, materials, etc.)
            context: Additional context or prior knowledge
            num_hypotheses: Target number of hypotheses (default 50)

        Returns:
            List of scored and ranked hypotheses
        """
        # Generate hypotheses using Opus 4.5
        response = await ai_service.generate_hypotheses(
            problem_statement=problem_statement,
            constraints=constraints,
            context=context,
            num_hypotheses=num_hypotheses,
        )

        # Parse the JSON response
        hypotheses = self._parse_hypotheses_response(response)

        # Sort by combined score
        hypotheses.sort(key=lambda h: h.combined_score, reverse=True)

        return hypotheses

    def _parse_hypotheses_response(self, response: str) -> list[Hypothesis]:
        """Parse the AI response into Hypothesis objects."""
        hypotheses = []

        try:
            # Try to extract JSON from the response
            # The response might have text around the JSON
            start = response.find('[')
            end = response.rfind(']') + 1
            if start != -1 and end > start:
                json_str = response[start:end]
                data = json.loads(json_str)

                for i, item in enumerate(data):
                    feasibility = item.get("feasibility", item.get("feasibility_score", 5))
                    novelty = item.get("novelty", item.get("novelty_score", 5))
                    impact = item.get("impact", item.get("impact_score", 5))

                    # Calculate combined score (weighted average)
                    combined = (feasibility * 0.3 + novelty * 0.3 + impact * 0.4)

                    hypothesis = Hypothesis(
                        id=f"hyp_{i+1:03d}",
                        title=item.get("title", item.get("hypothesis", f"Hypothesis {i+1}")[:80]),
                        statement=item.get("statement", item.get("hypothesis", "")),
                        rationale=item.get("rationale", item.get("scientific_rationale", "")),
                        feasibility=int(feasibility),
                        novelty=int(novelty),
                        impact=int(impact),
                        combined_score=round(combined, 1),
                        key_references=item.get("key_references", item.get("references", [])),
                        materials=item.get("materials", []),
                        next_steps=item.get("next_steps", item.get("suggested_next_steps", [])),
                        category=item.get("category", "general"),
                    )
                    hypotheses.append(hypothesis)

        except json.JSONDecodeError:
            # If JSON parsing fails, create a single hypothesis from the text
            hypotheses.append(Hypothesis(
                id="hyp_001",
                title="Analysis Result",
                statement=response[:500],
                rationale="See full analysis above",
                feasibility=5,
                novelty=5,
                impact=5,
                combined_score=5.0,
            ))

        return hypotheses

    async def synthesize_literature(
        self,
        problem_statement: str,
        hypotheses: list[Hypothesis],
    ) -> dict[str, Any]:
        """
        Synthesize relevant literature for the problem and hypotheses.

        Uses Claude Opus 4.5 to analyze and synthesize findings.
        """
        # Build context from top hypotheses
        top_hypotheses = hypotheses[:10]
        hypotheses_text = "\n".join([
            f"- {h.title}: {h.statement}"
            for h in top_hypotheses
        ])

        system = """You are a senior research scientist synthesizing literature for clean energy innovation.
Analyze the problem and hypotheses, then provide:
1. Summary of key findings from relevant literature
2. Areas of consensus in the field
3. Contradictory findings and possible explanations
4. Knowledge gaps that need research
5. Emerging trends and future directions

Be specific and cite relevant work by name/year when possible."""

        prompt = f"""Synthesize the relevant scientific literature for:

**Problem:** {problem_statement}

**Key Hypotheses Being Explored:**
{hypotheses_text}

Provide a comprehensive literature synthesis covering:
1. Key findings (with citations)
2. Areas of consensus
3. Contradictory findings
4. Knowledge gaps
5. Emerging trends

Format as JSON with fields: summary, consensus (list), contradictions (list), gaps (list), key_papers (list with title, authors, year, relevance_note)."""

        response = await ai_service.generate(
            prompt=prompt,
            system=system,
            model="opus",
            max_tokens=4096,
        )

        # Parse response
        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except json.JSONDecodeError:
            pass

        return {
            "summary": response,
            "consensus": [],
            "contradictions": [],
            "gaps": [],
            "key_papers": [],
        }

    async def analyze_patent_landscape(
        self,
        problem_statement: str,
        technology_keywords: list[str],
    ) -> dict[str, Any]:
        """
        Analyze the patent landscape for the problem area.

        Uses Claude Opus 4.5 to provide strategic patent analysis.
        """
        system = """You are a patent analyst specializing in clean energy technology.
Analyze the patent landscape and provide strategic insights on:
1. Overall patent density and trends
2. Key patent holders and their focus areas
3. White space opportunities (areas with limited patents)
4. Freedom to operate considerations
5. Emerging patent trends

Be strategic and actionable."""

        prompt = f"""Analyze the patent landscape for:

**Problem:** {problem_statement}

**Technology Keywords:** {', '.join(technology_keywords)}

Provide:
1. Overview of patent activity
2. Top patent holders (estimate counts and focus)
3. White space opportunities
4. Freedom to operate assessment
5. Patent filing recommendations

Format as JSON with fields: overview, total_patents (estimate), recent_patents (5yr, estimate), white_space_score (1-10), key_players (list), white_spaces (list), recommendations (list)."""

        response = await ai_service.generate(
            prompt=prompt,
            system=system,
            model="opus",
            max_tokens=2048,
        )

        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except json.JSONDecodeError:
            pass

        return {
            "overview": response,
            "total_patents": 0,
            "recent_patents": 0,
            "white_space_score": 5,
            "key_players": [],
            "white_spaces": [],
            "recommendations": [],
        }

    async def generate_executive_summary(
        self,
        problem_statement: str,
        hypotheses: list[Hypothesis],
        literature: dict[str, Any] | None,
        patents: dict[str, Any] | None,
    ) -> dict[str, Any]:
        """
        Generate executive summary and recommendations.

        Uses Claude Opus 4.5 for strategic synthesis.
        """
        top_hypotheses = hypotheses[:5]
        hypotheses_text = "\n".join([
            f"{i+1}. {h.title} (Score: {h.combined_score}/10): {h.statement[:200]}..."
            for i, h in enumerate(top_hypotheses)
        ])

        literature_summary = literature.get("summary", "No literature analysis available") if literature else "N/A"
        patent_summary = patents.get("overview", "No patent analysis available") if patents else "N/A"

        system = """You are a chief scientist preparing an executive summary for clean energy R&D leadership.
Synthesize all analyses into actionable strategic recommendations.
Be specific, prioritized, and consider resource constraints."""

        prompt = f"""Create an executive summary for this discovery:

**Problem:** {problem_statement}

**Top Hypotheses:**
{hypotheses_text}

**Literature Summary:** {literature_summary}

**Patent Landscape:** {patent_summary}

Provide:
1. Executive summary (2-3 paragraphs)
2. Top recommendation (most promising path)
3. Immediate actions (0-3 months, 3-5 items)
4. Medium-term actions (3-12 months, 3-5 items)
5. Long-term vision (1 paragraph)
6. Key risk factors (with mitigation strategies)

Format as JSON with fields: executive_summary, top_recommendation, immediate_actions (list), medium_term_actions (list), long_term_vision, risk_factors (list of objects with description, likelihood, impact, mitigation)."""

        response = await ai_service.generate(
            prompt=prompt,
            system=system,
            model="opus",
            max_tokens=3000,
        )

        try:
            start = response.find('{')
            end = response.rfind('}') + 1
            if start != -1 and end > start:
                return json.loads(response[start:end])
        except json.JSONDecodeError:
            pass

        return {
            "executive_summary": response,
            "top_recommendation": "See summary above",
            "immediate_actions": [],
            "medium_term_actions": [],
            "long_term_vision": "",
            "risk_factors": [],
        }

    async def run_full_discovery(
        self,
        discovery_id: str,
        problem_statement: str,
        constraints: dict[str, Any] | None = None,
        num_hypotheses: int = 50,
        progress_callback: Any | None = None,
    ) -> DiscoveryResult:
        """
        Run a complete discovery process.

        Steps:
        1. Generate hypotheses with Opus 4.5
        2. Synthesize relevant literature
        3. Analyze patent landscape
        4. Generate executive summary and recommendations

        Args:
            discovery_id: Unique identifier for this discovery
            problem_statement: The research problem
            constraints: Optional constraints
            num_hypotheses: Target number of hypotheses
            progress_callback: Optional async callback for progress updates

        Returns:
            Complete DiscoveryResult
        """
        start_time = datetime.utcnow()

        async def update_progress(status: DiscoveryStatus, percent: int, step: str, **kwargs):
            if progress_callback:
                progress = DiscoveryProgress(
                    status=status,
                    progress_percent=percent,
                    current_step=step,
                    **kwargs,
                )
                await progress_callback(progress)

        try:
            # Step 1: Generate hypotheses (0-40%)
            await update_progress(
                DiscoveryStatus.GENERATING_HYPOTHESES,
                5,
                "Initializing Claude Opus 4.5 for hypothesis generation..."
            )

            hypotheses = await self.generate_hypotheses(
                problem_statement=problem_statement,
                constraints=constraints,
                num_hypotheses=num_hypotheses,
            )

            await update_progress(
                DiscoveryStatus.GENERATING_HYPOTHESES,
                40,
                f"Generated {len(hypotheses)} hypotheses",
                hypotheses_generated=len(hypotheses),
            )

            # Step 2: Literature synthesis (40-60%)
            await update_progress(
                DiscoveryStatus.SEARCHING_LITERATURE,
                45,
                "Synthesizing relevant literature..."
            )

            literature = await self.synthesize_literature(
                problem_statement=problem_statement,
                hypotheses=hypotheses,
            )

            papers_count = len(literature.get("key_papers", []))
            await update_progress(
                DiscoveryStatus.SEARCHING_LITERATURE,
                60,
                f"Analyzed {papers_count} key papers",
                hypotheses_generated=len(hypotheses),
                papers_found=papers_count,
            )

            # Step 3: Patent analysis (60-80%)
            await update_progress(
                DiscoveryStatus.ANALYZING_PATENTS,
                65,
                "Analyzing patent landscape..."
            )

            # Extract keywords from top hypotheses
            keywords = list(set([
                word for h in hypotheses[:10]
                for word in h.title.lower().split()
                if len(word) > 4
            ]))[:10]

            patents = await self.analyze_patent_landscape(
                problem_statement=problem_statement,
                technology_keywords=keywords,
            )

            await update_progress(
                DiscoveryStatus.ANALYZING_PATENTS,
                80,
                "Patent analysis complete",
                hypotheses_generated=len(hypotheses),
                papers_found=papers_count,
                patents_found=patents.get("total_patents", 0),
            )

            # Step 4: Executive summary (80-100%)
            await update_progress(
                DiscoveryStatus.SYNTHESIZING,
                85,
                "Generating executive summary and recommendations..."
            )

            summary = await self.generate_executive_summary(
                problem_statement=problem_statement,
                hypotheses=hypotheses,
                literature=literature,
                patents=patents,
            )

            processing_time = (datetime.utcnow() - start_time).total_seconds()

            await update_progress(
                DiscoveryStatus.COMPLETED,
                100,
                "Discovery complete!",
                hypotheses_generated=len(hypotheses),
                papers_found=papers_count,
                patents_found=patents.get("total_patents", 0),
            )

            return DiscoveryResult(
                discovery_id=discovery_id,
                problem_statement=problem_statement,
                constraints=constraints or {},
                hypotheses=hypotheses,
                literature_synthesis=literature,
                patent_landscape=patents,
                materials_analysis=None,  # TODO: Add materials search
                executive_summary=summary.get("executive_summary", ""),
                top_recommendation=summary.get("top_recommendation", ""),
                immediate_actions=summary.get("immediate_actions", []),
                medium_term_actions=summary.get("medium_term_actions", []),
                long_term_vision=summary.get("long_term_vision", ""),
                risk_factors=summary.get("risk_factors", []),
                processing_time_seconds=processing_time,
                created_at=start_time,
            )

        except Exception as e:
            await update_progress(
                DiscoveryStatus.FAILED,
                0,
                f"Discovery failed: {str(e)}",
                error_message=str(e),
            )
            raise


# Singleton instance
discovery_engine = DiscoveryEngine()
